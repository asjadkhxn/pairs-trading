{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290202c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from arch import arch_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5999bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MISSINGâ€“DATA\n",
    "def handle_missing_data(df, max_ffill_days: int = 3):\n",
    "    \"\"\"\n",
    "    IV IMPUTATION using GARCH(1,1)\n",
    "    Method: Generalized Autoregressive Conditional Heteroskedasticity\n",
    "    - Standard approach for volatility imputation in quant finance\n",
    "    - Preserves volatility clustering and mean reversion\n",
    "    Reference: Engle (2001), \"GARCH 101: The Use of ARCH/GARCH Models in Applied Econometrics\"\n",
    "    \"\"\"\n",
    "    full_idx = pd.date_range(df.index.min().floor('T'),\n",
    "                             df.index.max().ceil('T'), \n",
    "                             freq='T', tz=df.index.tz)\n",
    "    full_idx = full_idx[full_idx.dayofweek < 5]\n",
    "    df_full = df.reindex(full_idx)\n",
    "    \n",
    "    raw_nan = df_full.isna().any(axis=1)\n",
    "    \n",
    "    mins_per_session = 375\n",
    "    ffill_limit = max_ffill_days * mins_per_session\n",
    "    df_tmp = df_full.fillna(method='ffill', limit=ffill_limit)\n",
    "    \n",
    "    df_filled = df_tmp.copy()\n",
    "    \n",
    "    for col in ['nifty', 'banknifty']:\n",
    "        series = df_tmp[col]\n",
    "        \n",
    "        if series.isna().any():\n",
    "            print(f\"Applying GARCH imputation to {col.upper()}...\")\n",
    "\n",
    "            available_data = series.dropna()\n",
    "            \n",
    "            if len(available_data) < 100:\n",
    "                df_filled[col] = series.interpolate(method='linear')\n",
    "                continue\n",
    "            \n",
    "            returns = available_data.pct_change().dropna() * 100 \n",
    "            \n",
    "            # Fit GARCH(1,1) model\n",
    "            try:\n",
    "                garch_model = arch_model(returns, vol='GARCH', p=1, q=1, rescale=False)\n",
    "                garch_fitted = garch_model.fit(disp='off')\n",
    "\n",
    "                last_level = available_data.iloc[-1]\n",
    "                last_return = returns.iloc[-1]\n",
    "\n",
    "                missing_mask = series.isna()\n",
    "                gap_labels = (missing_mask != missing_mask.shift()).cumsum()[missing_mask]\n",
    "                \n",
    "                for _, gap_idx in series[missing_mask].groupby(gap_labels).groups.items():\n",
    "                    if len(gap_idx) <= ffill_limit:\n",
    "                        continue  \n",
    "                    \n",
    "                    gap_length = len(gap_idx)\n",
    "                \n",
    "                    forecast = garch_fitted.forecast(horizon=min(gap_length, 1000), reindex=False)\n",
    "                    \n",
    "                    vol_forecast = np.sqrt(forecast.variance.values[-1])\n",
    "                    \n",
    "                    np.random.seed(42)  \n",
    " \n",
    "                    omega = garch_fitted.params['omega']\n",
    "                    alpha = garch_fitted.params['alpha[1]']\n",
    "                    beta = garch_fitted.params['beta[1]']\n",
    "                    \n",
    "                    current_level = last_level\n",
    "                    current_vol = vol_forecast[0] if len(vol_forecast) > 0 else np.std(returns)\n",
    "                    \n",
    "                    imputed_levels = []\n",
    "                    \n",
    "                    for i in range(gap_length):\n",
    "                        if i > 0:\n",
    "                            current_vol = np.sqrt(omega + alpha * (prev_return**2) + beta * (current_vol**2))\n",
    "                        \n",
    "                        random_return = np.random.normal(0, current_vol)\n",
    "                                               \n",
    "                        mean_reversion = 0.999 \n",
    "                        long_term_mean = available_data.mean()\n",
    "                        \n",
    "                        current_level = current_level * mean_reversion + (1-mean_reversion) * long_term_mean\n",
    "                        current_level = current_level * (1 + random_return/100)\n",
    "                        \n",
    "                        current_level = max(current_level, 0.01)\n",
    "                        \n",
    "                        imputed_levels.append(current_level)\n",
    "                        prev_return = random_return\n",
    "                    \n",
    "                    df_filled.loc[gap_idx, col] = imputed_levels\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"GARCH fitting failed for {col}, using linear interpolation: {e}\")\n",
    "                df_filled[col] = series.interpolate(method='linear')\n",
    "    \n",
    "    spread = df_filled['banknifty'] - df_filled['nifty']\n",
    "    imputed_spread = spread[raw_nan.reindex(df_filled.index, fill_value=False)]\n",
    "    \n",
    "    print(f\"\\nGARCH Imputation Results:\")\n",
    "    print(f\"Imputed {(raw_nan.reindex(df_filled.index, fill_value=False)).sum():,} rows\")\n",
    "    if len(imputed_spread) > 0:\n",
    "        print(f\"Imputed spread range: {imputed_spread.min():.4f} to {imputed_spread.max():.4f}\")\n",
    "        print(f\"Full data spread range: {spread.min():.4f} to {spread.max():.4f}\")\n",
    "    \n",
    "    df_out = df_filled.between_time('09:15', '15:30')\n",
    "    df_out['is_interpolated'] = raw_nan.reindex(df_out.index, fill_value=False).astype(np.int8)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATA LOADING\n",
    "def load_and_preprocess_data(file_path='data.parquet'):\n",
    "    df = pd.read_parquet(file_path)                       \n",
    "    df = df.between_time('09:15:00', '15:30:00')          \n",
    "    df = handle_missing_data(df)                         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SPREAD  &  Z-SCORE\n",
    "def calculate_spread_and_zscore(df, lookback_window=200):\n",
    "    df['spread']      = df['banknifty'] - df['nifty']\n",
    "\n",
    "    df['spread_mean'] = df['spread'].rolling(\n",
    "                            lookback_window, min_periods=lookback_window).mean()\n",
    "    df['spread_std']  = df['spread'].rolling(\n",
    "                            lookback_window, min_periods=lookback_window).std()\n",
    "\n",
    "    z_raw            = (df['spread'] - df['spread_mean']) / df['spread_std'].replace(0, np.nan)\n",
    "    df['z_score']    = z_raw.fillna(0.0)               \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. SIGNALS\n",
    "def generate_trading_signals(df, entry_threshold=2.0, exit_threshold=0.5):\n",
    "    z = df['z_score']\n",
    "\n",
    "    long_entry   =  (z < -entry_threshold)\n",
    "    short_entry  =  (z >  entry_threshold)\n",
    "    exit_signal  =  (z.abs() < exit_threshold)\n",
    "\n",
    "    raw_dir = np.where(exit_signal, 0,\n",
    "              np.where(long_entry,   1,\n",
    "              np.where(short_entry, -1, np.nan)))\n",
    "\n",
    "    df['position'] = (pd.Series(raw_dir, index=df.index)\n",
    "                        .ffill()               \n",
    "                        .fillna(0)             \n",
    "                        .astype(np.int8))\n",
    "\n",
    "    eod = df.index.time == pd.to_datetime('15:30:00').time()\n",
    "    df.loc[eod, 'position'] = 0\n",
    "\n",
    "    df['signal']          = df['position'].diff().fillna(df['position']).astype(np.int8)\n",
    "    df['position_change'] = df['signal']                                         # kept for metrics\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. P/L  \n",
    "def calculate_pnl(df, trade_cost_bps=0.0325):  \n",
    "    df['trade_pnl'] = 0.0\n",
    "    cumulative_pnl  = 0.0\n",
    "\n",
    "    open_pos        = 0\n",
    "    entry_spread    = entry_tte = entry_dir = None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        curr_pos = row['position']\n",
    "\n",
    "        # -------- ENTRY ------------------------------------------------------\n",
    "        enter = (open_pos == 0 and curr_pos != 0) or \\\n",
    "                (open_pos != 0 and np.sign(curr_pos) != np.sign(open_pos))\n",
    "\n",
    "        # -------- EXIT -------------------------------------------------------\n",
    "        exit_  = (open_pos != 0 and curr_pos == 0) or \\\n",
    "                 (open_pos != 0 and np.sign(curr_pos) != np.sign(open_pos))\n",
    "\n",
    "        if exit_:\n",
    "            spread_change = row['spread'] - entry_spread\n",
    "            avg_tte       = ((entry_tte + row['tte']) / 2.) ** 0.7\n",
    "            pnl           = spread_change * avg_tte * entry_dir\n",
    "            pnl          -= trade_cost_bps                   \n",
    "            df.at[idx, 'trade_pnl'] = pnl\n",
    "            cumulative_pnl         += pnl\n",
    "            open_pos = 0                                     \n",
    "        if enter:\n",
    "            entry_spread = row['spread']\n",
    "            entry_tte    = row['tte']\n",
    "            entry_dir    = curr_pos\n",
    "            open_pos     = curr_pos\n",
    "\n",
    "    df['cumulative_pnl'] = df['trade_pnl'].cumsum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.  PERFORMANCE  METRICS\n",
    "def calculate_performance_metrics(df):\n",
    "    total_pnl   = df['cumulative_pnl'].iloc[-1]\n",
    "    num_trades  = (df['trade_pnl'] != 0).sum()            \n",
    "\n",
    "    daily_pnl   = df['cumulative_pnl'].resample('D').last().diff().dropna()\n",
    "    sharpe      = (daily_pnl.mean() / daily_pnl.std() * np.sqrt(252)\n",
    "                   if daily_pnl.std() != 0 else 0)\n",
    "\n",
    "    equity      = df['cumulative_pnl']\n",
    "    running_max = equity.cummax()\n",
    "    drawdown    = equity - running_max\n",
    "    drawdown_pct= drawdown / running_max.replace(0, np.nan)\n",
    "    max_dd      = drawdown.min()\n",
    "    max_dd_pct  = drawdown_pct.min()\n",
    "\n",
    "    trade_pnls  = df.loc[df['trade_pnl'] != 0, 'trade_pnl']\n",
    "    win_rate    = (trade_pnls > 0).mean() if len(trade_pnls) else 0\n",
    "\n",
    "    return {\n",
    "        'Total P/L'          : total_pnl,\n",
    "        'Number of Trades'   : num_trades,\n",
    "        'Sharpe Ratio'       : sharpe,\n",
    "        'Max Drawdown (abs)' : max_dd,\n",
    "        'Win Rate'           : win_rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83430052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. PLOTS\n",
    "\n",
    "def plot_results(df):\n",
    "    \"\"\"\n",
    "    Plot key results\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "    # Plot 1: Spread and Z-Score\n",
    "    axes[0].plot(df.index, df['spread'], label='Spread', alpha=0.7)\n",
    "    axes[0].set_ylabel('Spread')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title('Bank Nifty - Nifty IV Spread')\n",
    "\n",
    "    ax0_twin = axes[0].twinx()\n",
    "    ax0_twin.plot(df.index, df['z_score'], color='red', label='Z-Score', alpha=0.7)\n",
    "    ax0_twin.axhline(y=2, color='r', linestyle='--', alpha=0.5)\n",
    "    ax0_twin.axhline(y=-2, color='r', linestyle='--', alpha=0.5)\n",
    "    ax0_twin.set_ylabel('Z-Score')\n",
    "    ax0_twin.legend()\n",
    "\n",
    "    # Plot 2: Positions\n",
    "    axes[1].plot(df.index, df['position'], label='Position', color='orange')\n",
    "    axes[1].set_ylabel('Position')\n",
    "    axes[1].set_title('Trading Positions')\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Plot 3: Cumulative P/L\n",
    "    axes[2].plot(df.index, df['cumulative_pnl'], label='Cumulative P/L', color='green')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].set_ylabel('Cumulative P/L')\n",
    "    axes[2].set_title('Strategy Performance')\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. MAIN\n",
    "def main():\n",
    "    df  = load_and_preprocess_data('data.parquet')\n",
    "    df  = calculate_spread_and_zscore(df, lookback_window=100)\n",
    "    df  = generate_trading_signals(df, entry_threshold=2.0, exit_threshold=0.5)\n",
    "    df  = calculate_pnl(df)\n",
    "    mts = calculate_performance_metrics(df)\n",
    "\n",
    "    for k, v in mts.items():\n",
    "        print(f'{k:22}: {v:,.4f}' if isinstance(v, float) else f'{k:22}: {v}')\n",
    "\n",
    "    plot_results(df)\n",
    "    return df, mts\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_results, performance = main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
