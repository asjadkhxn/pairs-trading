{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.api import OLS\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e47cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MISSINGâ€“DATA \n",
    "def handle_missing_data(df, max_ffill_days: int = 3):\n",
    "    \"\"\"\n",
    "    IV IMPUTATION using GARCH(1,1)\n",
    "    Method: Generalized Autoregressive Conditional Heteroskedasticity\n",
    "    - Standard approach for volatility imputation in quant finance\n",
    "    - Preserves volatility clustering and mean reversion\n",
    "    Reference: Engle (2001), \"GARCH 101: The Use of ARCH/GARCH Models in Applied Econometrics\"\n",
    "    \"\"\"\n",
    "    full_idx = pd.date_range(df.index.min().floor('T'),\n",
    "                            df.index.max().ceil('T'),\n",
    "                            freq='T', tz=df.index.tz)\n",
    "    full_idx = full_idx[full_idx.dayofweek < 5]\n",
    "    df_full = df.reindex(full_idx)\n",
    "    \n",
    "    raw_nan = df_full.isna().any(axis=1)\n",
    "    mins_per_session = 375\n",
    "    ffill_limit = max_ffill_days * mins_per_session\n",
    "    df_tmp = df_full.fillna(method='ffill', limit=ffill_limit)\n",
    "    df_filled = df_tmp.copy()\n",
    "    \n",
    "    for col in ['nifty', 'banknifty']:\n",
    "        series = df_tmp[col]\n",
    "        if series.isna().any():\n",
    "            print(f\"Applying GARCH imputation to {col.upper()}...\")\n",
    "            available_data = series.dropna()\n",
    "            if len(available_data) < 100:\n",
    "                df_filled[col] = series.interpolate(method='linear')\n",
    "                continue\n",
    "\n",
    "            returns = available_data.pct_change().dropna() * 100 \n",
    "            \n",
    "            # Fit GARCH(1,1) model\n",
    "            try:\n",
    "                garch_model = arch_model(returns, vol='GARCH', p=1, q=1, rescale=False)\n",
    "                garch_fitted = garch_model.fit(disp='off')\n",
    "\n",
    "                last_level = available_data.iloc[-1]\n",
    "                last_return = returns.iloc[-1]\n",
    "\n",
    "                missing_mask = series.isna()\n",
    "                gap_labels = (missing_mask != missing_mask.shift()).cumsum()[missing_mask]\n",
    "                \n",
    "                for _, gap_idx in series[missing_mask].groupby(gap_labels).groups.items():\n",
    "                    if len(gap_idx) <= ffill_limit:\n",
    "                        continue \n",
    "                        \n",
    "                    gap_length = len(gap_idx)\n",
    "                    \n",
    "                    forecast = garch_fitted.forecast(horizon=min(gap_length, 1000), reindex=False)\n",
    "                    \n",
    "                    vol_forecast = np.sqrt(forecast.variance.values[-1])\n",
    "                    np.random.seed(42) \n",
    "\n",
    "                    omega = garch_fitted.params['omega']\n",
    "                    alpha = garch_fitted.params['alpha[1]']\n",
    "                    beta = garch_fitted.params['beta[1]']\n",
    "\n",
    "                    current_level = last_level\n",
    "                    current_vol = vol_forecast[0] if len(vol_forecast) > 0 else np.std(returns)\n",
    "                    \n",
    "                    imputed_levels = []\n",
    "                    for i in range(gap_length):\n",
    "                        if i > 0:\n",
    "                            current_vol = np.sqrt(omega + alpha * (prev_return**2) + beta * (current_vol**2))\n",
    "                        \n",
    "                        # Generate return with current volatility\n",
    "                        random_return = np.random.normal(0, current_vol)\n",
    "                        \n",
    "                        mean_reversion = 0.999 \n",
    "                        long_term_mean = available_data.mean()\n",
    "                        current_level = current_level * mean_reversion + (1-mean_reversion) * long_term_mean\n",
    "                        current_level = current_level * (1 + random_return/100)\n",
    "                        current_level = max(current_level, 0.01)\n",
    "                        \n",
    "                        imputed_levels.append(current_level)\n",
    "                        prev_return = random_return\n",
    "\n",
    "                    df_filled.loc[gap_idx, col] = imputed_levels\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"GARCH fitting failed for {col}, using linear interpolation: {e}\")\n",
    "                df_filled[col] = series.interpolate(method='linear')\n",
    "    \n",
    "    spread = df_filled['banknifty'] - df_filled['nifty']\n",
    "    imputed_spread = spread[raw_nan.reindex(df_filled.index, fill_value=False)]\n",
    "    \n",
    "    print(f\"\\nGARCH Imputation Results:\")\n",
    "    print(f\"Imputed {(raw_nan.reindex(df_filled.index, fill_value=False)).sum():,} rows\")\n",
    "    if len(imputed_spread) > 0:\n",
    "        print(f\"Imputed spread range: {imputed_spread.min():.4f} to {imputed_spread.max():.4f}\")\n",
    "        print(f\"Full data spread range: {spread.min():.4f} to {spread.max():.4f}\")\n",
    "    \n",
    "    df_out = df_filled.between_time('09:15', '15:30')\n",
    "    df_out['is_interpolated'] = raw_nan.reindex(df_out.index, fill_value=False).astype(np.int8)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATA LOADING\n",
    "def load_and_preprocess_data(file_path='data.parquet'):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df = df.between_time('09:15:00', '15:30:00')\n",
    "    df = handle_missing_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. COINTEGRATION & SIGNALS\n",
    "def calculate_cointegration_signals(df, lookback_window=252):\n",
    "    \"\"\"\n",
    "    Cointegration-based signal generation\n",
    "    Research shows this is the most efficient method for pairs trading\n",
    "    \"\"\"\n",
    "    df['spread'] = df['banknifty'] - df['nifty']\n",
    "    df['coint_signal'] = 0.0\n",
    "    df['hedge_ratio'] = np.nan\n",
    "    df['residual'] = np.nan\n",
    "    df['cointegrated'] = False\n",
    "    \n",
    "    total_iterations = len(df) - lookback_window\n",
    "    print(f\"Calculating cointegration signals for {total_iterations:,} observations...\")\n",
    "\n",
    "    progress_bar = tqdm(\n",
    "        total=total_iterations, \n",
    "        desc=\"Cointegration Analysis\", \n",
    "        unit=\"obs\",\n",
    "        ncols=100,\n",
    "        bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
    "    )\n",
    "    \n",
    "    for i in range(lookback_window, len(df)):\n",
    "        lookback_data = df.iloc[i-lookback_window:i]\n",
    "        \n",
    "        try:\n",
    "            score, pvalue, _ = coint(lookback_data['banknifty'], lookback_data['nifty'])\n",
    "            \n",
    "            if pvalue < 0.05:  \n",
    "                df.iloc[i, df.columns.get_loc('cointegrated')] = True\n",
    "                \n",
    "                y = lookback_data['banknifty']\n",
    "                x = lookback_data['nifty']\n",
    "                model = OLS(y, x).fit()\n",
    "                hedge_ratio = model.params[0]\n",
    "                \n",
    "                current_residual = df.iloc[i]['banknifty'] - hedge_ratio * df.iloc[i]['nifty']\n",
    "                residual_series = lookback_data['banknifty'] - hedge_ratio * lookback_data['nifty']\n",
    "                residual_mean = residual_series.mean()\n",
    "                residual_std = residual_series.std()\n",
    "                \n",
    "                if residual_std > 0:\n",
    "                    signal = (current_residual - residual_mean) / residual_std\n",
    "                    df.iloc[i, df.columns.get_loc('coint_signal')] = signal\n",
    "                    df.iloc[i, df.columns.get_loc('hedge_ratio')] = hedge_ratio\n",
    "                    df.iloc[i, df.columns.get_loc('residual')] = current_residual\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    cointegrated_periods = df['cointegrated'].sum()\n",
    "    print(f\"Cointegration analysis complete. Found {cointegrated_periods:,} cointegrated periods.\")\n",
    "\n",
    "    df['coint_signal'] = df['coint_signal'].fillna(0.0)\n",
    "    df['hedge_ratio'] = df['hedge_ratio'].fillna(method='ffill')\n",
    "    df['cointegrated'] = df['cointegrated'].fillna(False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90734109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. SIGNALS\n",
    "def generate_trading_signals(df, entry_threshold=1.5, exit_threshold=0.3):\n",
    "   \n",
    "    signal = df['coint_signal']\n",
    "    cointegrated = df['cointegrated']\n",
    "    \n",
    "    # Only generate signals when pairs are cointegrated\n",
    "    long_entry = (signal < -entry_threshold) & cointegrated\n",
    "    short_entry = (signal > entry_threshold) & cointegrated\n",
    "    exit_signal = (signal.abs() < exit_threshold) | (~cointegrated)\n",
    "    \n",
    "    raw_dir = np.where(exit_signal, 0,\n",
    "                      np.where(long_entry, 1,\n",
    "                              np.where(short_entry, -1, np.nan)))\n",
    "    \n",
    "    df['position'] = (pd.Series(raw_dir, index=df.index)\n",
    "                     .ffill()  \n",
    "                     .fillna(0)  \n",
    "                     .astype(np.int8))\n",
    "    \n",
    "  \n",
    "    eod = df.index.time == pd.to_datetime('15:30:00').time()\n",
    "    df.loc[eod, 'position'] = 0\n",
    "    \n",
    "    df['signal'] = df['position'].diff().fillna(df['position']).astype(np.int8)\n",
    "    df['position_change'] = df['signal']  \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5279273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. P/L \n",
    "def calculate_pnl(df, trade_cost_bps=0.02):\n",
    "    df['trade_pnl'] = 0.0\n",
    "    cumulative_pnl = 0.0\n",
    "    open_pos = 0\n",
    "    entry_spread = entry_tte = entry_dir = None\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        curr_pos = row['position']\n",
    "        \n",
    "        # -------- ENTRY ------------------------------------------------------\n",
    "        enter = (open_pos == 0 and curr_pos != 0) or \\\n",
    "                (open_pos != 0 and np.sign(curr_pos) != np.sign(open_pos))\n",
    "        \n",
    "        # -------- EXIT -------------------------------------------------------\n",
    "        exit_ = (open_pos != 0 and curr_pos == 0) or \\\n",
    "                (open_pos != 0 and np.sign(curr_pos) != np.sign(open_pos))\n",
    "        \n",
    "        if exit_:\n",
    "            spread_change = row['spread'] - entry_spread\n",
    "            avg_tte = ((entry_tte + row['tte']) / 2.) ** 0.7\n",
    "            pnl = spread_change * avg_tte * entry_dir\n",
    "            pnl -= trade_cost_bps  \n",
    "            \n",
    "            df.at[idx, 'trade_pnl'] = pnl\n",
    "            cumulative_pnl += pnl\n",
    "            open_pos = 0  \n",
    "        \n",
    "        if enter:\n",
    "            entry_spread = row['spread']\n",
    "            entry_tte = row['tte']\n",
    "            entry_dir = curr_pos\n",
    "            open_pos = curr_pos\n",
    "    \n",
    "    df['cumulative_pnl'] = df['trade_pnl'].cumsum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b42bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. PERFORMANCE METRICS \n",
    "def calculate_performance_metrics(df):\n",
    "    total_pnl = df['cumulative_pnl'].iloc[-1]\n",
    "    num_trades = (df['trade_pnl'] != 0).sum() \n",
    "    \n",
    "    daily_pnl = df['cumulative_pnl'].resample('D').last().diff().dropna()\n",
    "    sharpe = (daily_pnl.mean() / daily_pnl.std() * np.sqrt(252)\n",
    "              if daily_pnl.std() != 0 else 0)\n",
    "    \n",
    "    equity = df['cumulative_pnl']\n",
    "    running_max = equity.cummax()\n",
    "    drawdown = equity - running_max\n",
    "    drawdown_pct = drawdown / running_max.replace(0, np.nan)\n",
    "    max_dd = drawdown.min()\n",
    "    max_dd_pct = drawdown_pct.min()\n",
    "    \n",
    "    trade_pnls = df.loc[df['trade_pnl'] != 0, 'trade_pnl']\n",
    "    win_rate = (trade_pnls > 0).mean() if len(trade_pnls) else 0\n",
    "    \n",
    "    return {\n",
    "        'Total P/L': total_pnl,\n",
    "        'Number of Trades': num_trades,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Max Drawdown (abs)': max_dd,\n",
    "        'Win Rate': win_rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931208ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. PLOTS \n",
    "def plot_results(df):\n",
    "    \"\"\"\n",
    "    Plot key results\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 16))\n",
    "    \n",
    "    # Plot 1: Spread and Cointegration Signal\n",
    "    axes[0].plot(df.index, df['spread'], label='Spread', alpha=0.7)\n",
    "    axes[0].set_ylabel('Spread')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title('Bank Nifty - Nifty IV Spread')\n",
    "    \n",
    "    ax0_twin = axes[0].twinx()\n",
    "    ax0_twin.plot(df.index, df['coint_signal'], color='red', label='Cointegration Signal', alpha=0.7)\n",
    "    ax0_twin.axhline(y=1.5, color='r', linestyle='--', alpha=0.5)\n",
    "    ax0_twin.axhline(y=-1.5, color='r', linestyle='--', alpha=0.5)\n",
    "    ax0_twin.set_ylabel('Cointegration Signal')\n",
    "    ax0_twin.legend()\n",
    "    \n",
    "    # Plot 2: Cointegration Status\n",
    "    axes[1].fill_between(df.index, 0, df['cointegrated'].astype(int), \n",
    "                        alpha=0.3, color='green', label='Cointegrated Periods')\n",
    "    axes[1].set_ylabel('Cointegrated')\n",
    "    axes[1].set_title('Cointegration Status')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # Plot 3: Positions\n",
    "    axes[2].plot(df.index, df['position'], label='Position', color='orange')\n",
    "    axes[2].set_ylabel('Position')\n",
    "    axes[2].set_title('Trading Positions')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    # Plot 4: Cumulative P/L\n",
    "    axes[3].plot(df.index, df['cumulative_pnl'], label='Cumulative P/L', color='green')\n",
    "    axes[3].set_xlabel('Date')\n",
    "    axes[3].set_ylabel('Cumulative P/L')\n",
    "    axes[3].set_title('Cointegration Strategy Performance')\n",
    "    axes[3].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. MAIN \n",
    "def main():\n",
    "    df = load_and_preprocess_data('data.parquet')\n",
    "    df = calculate_cointegration_signals(df, lookback_window=252)\n",
    "    df = generate_trading_signals(df, entry_threshold=1.5, exit_threshold=0.3)\n",
    "    df = calculate_pnl(df)\n",
    "    \n",
    "    mts = calculate_performance_metrics(df)\n",
    "\n",
    "    print(\"COINTEGRATION-BASED PAIRS TRADING STRATEGY\")\n",
    "    for k, v in mts.items():\n",
    "        print(f'{k:22}: {v:,.4f}' if isinstance(v, float) else f'{k:22}: {v}')\n",
    "    \n",
    "    plot_results(df)\n",
    "    \n",
    "    return df, mts\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_results, performance = main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
